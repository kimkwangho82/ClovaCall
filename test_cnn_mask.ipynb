{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pad_mask(lengths, xs=None, length_dim=-1):\n",
    "    \"\"\"Make mask tensor containing indices of padded part.\n",
    "    Args:\n",
    "        lengths (LongTensor or List): Batch of lengths (B,).\n",
    "        xs (Tensor, optional): The reference tensor.\n",
    "            If set, masks will be the same shape as this tensor.\n",
    "        length_dim (int, optional): Dimension indicator of the above tensor.\n",
    "            See the example.\n",
    "    Returns:\n",
    "        Tensor: Mask tensor containing indices of padded part.\n",
    "                dtype=torch.uint8 in PyTorch 1.2-\n",
    "                dtype=torch.bool in PyTorch 1.2+ (including 1.2)\n",
    "    Examples:\n",
    "        With only lengths.\n",
    "        >>> lengths = [5, 3, 2]\n",
    "        >>> make_non_pad_mask(lengths)\n",
    "        masks = [[0, 0, 0, 0 ,0],\n",
    "                 [0, 0, 0, 1, 1],\n",
    "                 [0, 0, 1, 1, 1]]\n",
    "        With the reference tensor.\n",
    "        >>> xs = torch.zeros((3, 2, 4))\n",
    "        >>> make_pad_mask(lengths, xs)\n",
    "        tensor([[[0, 0, 0, 0],\n",
    "                 [0, 0, 0, 0]],\n",
    "                [[0, 0, 0, 1],\n",
    "                 [0, 0, 0, 1]],\n",
    "                [[0, 0, 1, 1],\n",
    "                 [0, 0, 1, 1]]], dtype=torch.uint8)\n",
    "        >>> xs = torch.zeros((3, 2, 6))\n",
    "        >>> make_pad_mask(lengths, xs)\n",
    "        tensor([[[0, 0, 0, 0, 0, 1],\n",
    "                 [0, 0, 0, 0, 0, 1]],\n",
    "                [[0, 0, 0, 1, 1, 1],\n",
    "                 [0, 0, 0, 1, 1, 1]],\n",
    "                [[0, 0, 1, 1, 1, 1],\n",
    "                 [0, 0, 1, 1, 1, 1]]], dtype=torch.uint8)\n",
    "        With the reference tensor and dimension indicator.\n",
    "        >>> xs = torch.zeros((3, 6, 6))\n",
    "        >>> make_pad_mask(lengths, xs, 1)\n",
    "        tensor([[[0, 0, 0, 0, 0, 0],\n",
    "                 [0, 0, 0, 0, 0, 0],\n",
    "                 [0, 0, 0, 0, 0, 0],\n",
    "                 [0, 0, 0, 0, 0, 0],\n",
    "                 [0, 0, 0, 0, 0, 0],\n",
    "                 [1, 1, 1, 1, 1, 1]],\n",
    "                [[0, 0, 0, 0, 0, 0],\n",
    "                 [0, 0, 0, 0, 0, 0],\n",
    "                 [0, 0, 0, 0, 0, 0],\n",
    "                 [1, 1, 1, 1, 1, 1],\n",
    "                 [1, 1, 1, 1, 1, 1],\n",
    "                 [1, 1, 1, 1, 1, 1]],\n",
    "                [[0, 0, 0, 0, 0, 0],\n",
    "                 [0, 0, 0, 0, 0, 0],\n",
    "                 [1, 1, 1, 1, 1, 1],\n",
    "                 [1, 1, 1, 1, 1, 1],\n",
    "                 [1, 1, 1, 1, 1, 1],\n",
    "                 [1, 1, 1, 1, 1, 1]]], dtype=torch.uint8)\n",
    "        >>> make_pad_mask(lengths, xs, 2)\n",
    "        tensor([[[0, 0, 0, 0, 0, 1],\n",
    "                 [0, 0, 0, 0, 0, 1],\n",
    "                 [0, 0, 0, 0, 0, 1],\n",
    "                 [0, 0, 0, 0, 0, 1],\n",
    "                 [0, 0, 0, 0, 0, 1],\n",
    "                 [0, 0, 0, 0, 0, 1]],\n",
    "                [[0, 0, 0, 1, 1, 1],\n",
    "                 [0, 0, 0, 1, 1, 1],\n",
    "                 [0, 0, 0, 1, 1, 1],\n",
    "                 [0, 0, 0, 1, 1, 1],\n",
    "                 [0, 0, 0, 1, 1, 1],\n",
    "                 [0, 0, 0, 1, 1, 1]],\n",
    "                [[0, 0, 1, 1, 1, 1],\n",
    "                 [0, 0, 1, 1, 1, 1],\n",
    "                 [0, 0, 1, 1, 1, 1],\n",
    "                 [0, 0, 1, 1, 1, 1],\n",
    "                 [0, 0, 1, 1, 1, 1],\n",
    "                 [0, 0, 1, 1, 1, 1]]], dtype=torch.uint8)\n",
    "    \"\"\"\n",
    "    if length_dim == 0:\n",
    "        raise ValueError(\"length_dim cannot be 0: {}\".format(length_dim))\n",
    "\n",
    "    if not isinstance(lengths, list):\n",
    "        lengths = lengths.tolist()\n",
    "    bs = int(len(lengths))\n",
    "    if xs is None:\n",
    "        maxlen = int(max(lengths))\n",
    "    else:\n",
    "        maxlen = xs.size(length_dim)\n",
    "\n",
    "    seq_range = torch.arange(0, maxlen, dtype=torch.int64)\n",
    "    seq_range_expand = seq_range.unsqueeze(0).expand(bs, maxlen)\n",
    "    seq_length_expand = seq_range_expand.new(lengths).unsqueeze(-1)\n",
    "    mask = seq_range_expand >= seq_length_expand\n",
    "\n",
    "    if xs is not None:\n",
    "        assert xs.size(0) == bs, (xs.size(0), bs)\n",
    "\n",
    "        if length_dim < 0:\n",
    "            length_dim = xs.dim() + length_dim\n",
    "        # ind = (:, None, ..., None, :, , None, ..., None)\n",
    "        ind = tuple(\n",
    "            slice(None) if i in (0, length_dim) else None for i in range(xs.dim())\n",
    "        )\n",
    "        mask = mask[ind].expand_as(xs).to(xs.device)\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pre_hook(\n",
    "    state_dict,\n",
    "    prefix,\n",
    "    local_metadata,\n",
    "    strict,\n",
    "    missing_keys,\n",
    "    unexpected_keys,\n",
    "    error_msgs,\n",
    "):\n",
    "    \"\"\"Perform pre-hook in load_state_dict for backward compatibility.\n",
    "    Note:\n",
    "        We saved self.pe until v.0.5.2 but we have omitted it later.\n",
    "        Therefore, we remove the item \"pe\" from `state_dict` for backward compatibility.\n",
    "    \"\"\"\n",
    "    k = prefix + \"pe\"\n",
    "    if k in state_dict:\n",
    "        state_dict.pop(k)\n",
    "\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    \"\"\"Positional encoding.\n",
    "    :param int d_model: embedding dim\n",
    "    :param float dropout_rate: dropout rate\n",
    "    :param int max_len: maximum input length\n",
    "    :param reverse: whether to reverse the input position\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, dropout_rate, max_len=5000, reverse=False):\n",
    "        \"\"\"Construct an PositionalEncoding object.\"\"\"\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.reverse = reverse\n",
    "        self.xscale = math.sqrt(self.d_model)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout_rate)\n",
    "        self.pe = None\n",
    "        self.extend_pe(torch.tensor(0.0).expand(1, max_len))\n",
    "        self._register_load_state_dict_pre_hook(_pre_hook)\n",
    "\n",
    "    def extend_pe(self, x):\n",
    "        \"\"\"Reset the positional encodings.\"\"\"\n",
    "        if self.pe is not None:\n",
    "            if self.pe.size(1) >= x.size(1):\n",
    "                if self.pe.dtype != x.dtype or self.pe.device != x.device:\n",
    "                    self.pe = self.pe.to(dtype=x.dtype, device=x.device)\n",
    "                return\n",
    "        pe = torch.zeros(x.size(1), self.d_model)\n",
    "        if self.reverse:\n",
    "            position = torch.arange(\n",
    "                x.size(1) - 1, -1, -1.0, dtype=torch.float32\n",
    "            ).unsqueeze(1)\n",
    "        else:\n",
    "            position = torch.arange(0, x.size(1), dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, self.d_model, 2, dtype=torch.float32)\n",
    "            * -(math.log(10000.0) / self.d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.pe = pe.to(device=x.device, dtype=x.dtype)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"Add positional encoding.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input. Its shape is (batch, time, ...)\n",
    "        Returns:\n",
    "            torch.Tensor: Encoded tensor. Its shape is (batch, time, ...)\n",
    "        \"\"\"\n",
    "        self.extend_pe(x)\n",
    "        x = x * self.xscale + self.pe[:, : x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dSubsampling(torch.nn.Module):\n",
    "    \"\"\"Convolutional 2D subsampling (to 1/4 length).\n",
    "    :param int idim: input dim\n",
    "    :param int odim: output dim\n",
    "    :param flaot dropout_rate: dropout rate\n",
    "    :param torch.nn.Module pos_enc: custom position encoding layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, idim, odim, dropout_rate, pos_enc=None):\n",
    "        \"\"\"Construct an Conv2dSubsampling object.\"\"\"\n",
    "        super(Conv2dSubsampling, self).__init__()\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, odim, 3, 2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(odim, odim, 3, 2),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.out = torch.nn.Sequential(\n",
    "            torch.nn.Linear(odim * (((idim - 1) // 2 - 1) // 2), odim),\n",
    "            pos_enc if pos_enc is not None else PositionalEncoding(odim, dropout_rate),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, x_mask):\n",
    "        \"\"\"Subsample x.\n",
    "        :param torch.Tensor x: input tensor\n",
    "        :param torch.Tensor x_mask: input mask\n",
    "        :return: subsampled x and mask\n",
    "        :rtype Tuple[torch.Tensor, torch.Tensor]\n",
    "        \"\"\"\n",
    "        x = x.unsqueeze(1)  # (b, c, t, f)\n",
    "        x = self.conv(x)\n",
    "        b, c, t, f = x.size()\n",
    "        x = self.out(x.transpose(1, 2).contiguous().view(b, t, c * f))\n",
    "        if x_mask is None:\n",
    "            return x, None\n",
    "        return x, x_mask[:, :, :-2:2][:, :, :-2:2]\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"Subsample x.\n",
    "        When reset_parameters() is called, if use_scaled_pos_enc is used,\n",
    "            return the positioning encoding.\n",
    "        \"\"\"\n",
    "        if key != -1:\n",
    "            raise NotImplementedError(\"Support only `-1` (for `reset_parameters`).\")\n",
    "        return self.out[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 100, 80])\n",
      "masks :  torch.Size([2, 1, 3]) tensor([[[ True,  True,  True]],\n",
      "\n",
      "        [[ True, False, False]]])\n",
      "masks :  torch.Size([2, 1, 3]) tensor([[[ True,  True,  True]],\n",
      "\n",
      "        [[ True, False, False]]])\n",
      "torch.Size([2, 1, 3])\n",
      "torch.Size([2, 24, 256]) None\n",
      "tensor([[[-0.5961,  3.3177,  1.3302,  ..., -0.2452, -1.8144,  1.1807],\n",
      "         [-0.1751,  1.2290,  2.6446,  ...,  0.9326, -0.4382,  2.2329],\n",
      "         [-0.4486,  1.2248,  4.6761,  ..., -0.9271, -2.5451,  2.6658],\n",
      "         ...,\n",
      "         [ 3.6047, -1.6392,  4.5471,  ...,  0.8551, -2.1646,  4.8300],\n",
      "         [ 0.3301, -0.1814,  3.3958,  ...,  2.2957,  0.6581,  1.5172],\n",
      "         [-2.6082,  1.0390,  2.9837,  ..., -0.7914,  0.6395,  1.6098]],\n",
      "\n",
      "        [[ 0.1180,  1.8792,  0.8971,  ...,  1.0685,  0.1458,  1.9280],\n",
      "         [-0.3352,  4.1133,  3.1011,  ...,  0.0444, -1.7025,  0.0000],\n",
      "         [ 2.0404,  0.9817,  1.4435,  ...,  0.0506,  0.4475,  0.0413],\n",
      "         ...,\n",
      "         [ 0.4358,  1.2010,  2.8558,  ...,  2.9814, -1.7781,  3.9229],\n",
      "         [-1.5750, -0.1699,  1.2337,  ...,  0.7501, -1.9158,  3.4664],\n",
      "         [-0.2183,  0.7677,  2.0892,  ...,  1.6367,  0.4180,  3.2149]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# Sample DATA\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "# |spect| = (Seq_Len, Feat_Dim)\n",
    "spect = np.random.rand(2, 100, 80) \n",
    "spect = np.log1p(spect)\n",
    "\n",
    "x = spect\n",
    "\n",
    "mean = np.mean(x, axis=1, keepdims=True)\n",
    "std = np.std(x, axis=1, ddof=1, keepdims=True)\n",
    "std = np.clip(std, a_min=1e-20, a_max=None)\n",
    "\n",
    "x -= mean\n",
    "x = x / std\n",
    "\n",
    "\n",
    "\n",
    "x = torch.FloatTensor(x)\n",
    "print(x.size())\n",
    "\n",
    "ilens = [3, 1]\n",
    "\n",
    "masks = (~make_pad_mask(ilens)[:, None, :])\n",
    "print(\"masks : \", masks.size(), masks)\n",
    "\n",
    "masks = (~make_pad_mask(ilens)).unsqueeze(1)\n",
    "print(\"masks : \", masks.size(), masks)\n",
    "\n",
    "print(masks[:, -1:, :].size())\n",
    "\n",
    "\n",
    "conv = Conv2dSubsampling(idim=80, odim=256, dropout_rate=0.1)\n",
    "\n",
    "\n",
    "\n",
    "r, r_mask = conv(x, x_mask=None)\n",
    "print(r.size(), r_mask)\n",
    "print(r)\n",
    "\n",
    "\n",
    "idim = 100\n",
    "size = (((idim - 1) // 2 - 1) // 2)\n",
    "print(size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture",
   "language": "python",
   "name": "lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
